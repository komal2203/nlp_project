{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "15951014",
      "metadata": {
        "id": "15951014"
      },
      "source": [
        "# Including nesseccery libraries:\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f9cb554",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0f9cb554",
        "outputId": "b10e98a4-4097-460c-ce59-dcf240b572c5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from matplotlib import style\n",
        "style.use('ggplot')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "from wordcloud import WordCloud\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay,log_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d3f987a4",
      "metadata": {
        "id": "d3f987a4"
      },
      "source": [
        "# Data loading:\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d47d982",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "0d47d982",
        "outputId": "af5db85b-7f9d-4db3-d788-5cdaa70a2263"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'COVID-hate.csv'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-e2878fe39e49>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcovid_hate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'COVID-hate.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'COVID-hate.csv'"
          ]
        }
      ],
      "source": [
        "covid_hate = pd.read_csv('COVID-hate.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e435a772",
      "metadata": {
        "id": "e435a772"
      },
      "outputs": [],
      "source": [
        "covid_hate.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78c47ef5",
      "metadata": {
        "id": "78c47ef5"
      },
      "outputs": [],
      "source": [
        "covid_hate.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2770363",
      "metadata": {
        "id": "b2770363"
      },
      "source": [
        "# Data preprocessing:\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1912fed",
      "metadata": {
        "id": "b1912fed"
      },
      "outputs": [],
      "source": [
        "print(covid_hate['Text'].iloc[0],\"\\n\")\n",
        "print(covid_hate['Text'].iloc[1],\"\\n\")\n",
        "print(covid_hate['Text'].iloc[2],\"\\n\")\n",
        "print(covid_hate['Text'].iloc[3],\"\\n\")\n",
        "print(covid_hate['Text'].iloc[4],\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1b2398f",
      "metadata": {
        "id": "a1b2398f"
      },
      "outputs": [],
      "source": [
        " def data_preprocessing(data):\n",
        "    # Initialize the lemmatizer and stop words\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "\n",
        "    #Convert to lowercase\n",
        "    data = data.lower()\n",
        "\n",
        "    # Remove non-alphabetic characters\n",
        "    data = re.sub(r'[^a-zA-Z\\s]', '', data)\n",
        "\n",
        "    # Remove extra spaces\n",
        "    data = re.sub(r'\\s+', ' ', data).strip()\n",
        "\n",
        "    # Tokenize the data\n",
        "    data_tokens = word_tokenize(data)\n",
        "\n",
        "    # Lemmatize and remove stop words\n",
        "    filtered_data = [lemmatizer.lemmatize(w) for w in data_tokens if w not in stop_words]\n",
        "\n",
        "    # Return the processed data as a single string\n",
        "    return \" \".join(filtered_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "nKm_sL9lUk1O",
      "metadata": {
        "id": "nKm_sL9lUk1O"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9872c91",
      "metadata": {
        "id": "a9872c91"
      },
      "outputs": [],
      "source": [
        "covid_hate.Text = covid_hate['Text'].apply(data_preprocessing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "befa3be4",
      "metadata": {
        "id": "befa3be4"
      },
      "outputs": [],
      "source": [
        "covid_hate = covid_hate.drop_duplicates('Text')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5aa44976",
      "metadata": {
        "id": "5aa44976"
      },
      "outputs": [],
      "source": [
        "print(covid_hate['Text'].iloc[0],\"\\n\")\n",
        "print(covid_hate['Text'].iloc[1],\"\\n\")\n",
        "print(covid_hate['Text'].iloc[2],\"\\n\")\n",
        "print(covid_hate['Text'].iloc[3],\"\\n\")\n",
        "print(covid_hate['Text'].iloc[4],\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "560fbed3",
      "metadata": {
        "id": "560fbed3"
      },
      "source": [
        "# Data Visualizing:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24746a93",
      "metadata": {
        "id": "24746a93"
      },
      "outputs": [],
      "source": [
        "covid_hate.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "531cf6d3",
      "metadata": {
        "id": "531cf6d3"
      },
      "outputs": [],
      "source": [
        "covid_hate['label'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b49e103c",
      "metadata": {
        "id": "b49e103c"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize = (5,5))\n",
        "sns.countplot(x = 'label',data = covid_hate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e000d47",
      "metadata": {
        "id": "7e000d47"
      },
      "outputs": [],
      "source": [
        "covid_hate = covid_hate[covid_hate['label'] != 2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e0d0110",
      "metadata": {
        "id": "5e0d0110"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize = (7,7))\n",
        "colors = (\"red\",\"gold\")\n",
        "wp = {'linewidth' : 2,'edgecolor':\"black\"}\n",
        "tags = covid_hate['label'].value_counts()\n",
        "explode = (0.1,0.1)\n",
        "tags.plot(kind = 'pie',autopct = '%1.1f%%',shadow = True,colors = colors,startangle = 90,\n",
        "         wedgeprops = wp,explode = explode,label = '')\n",
        "plt.title('Distribution of Labels')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5545f5e1",
      "metadata": {
        "id": "5545f5e1"
      },
      "outputs": [],
      "source": [
        "text = ' '.join([word for word in covid_hate['Text']])\n",
        "plt.figure(figsize = (20,15),facecolor = 'None')\n",
        "wordcloud = WordCloud(max_words = 500,width = 1600,height= 800).generate(text)\n",
        "plt.imshow(wordcloud,interpolation = 'bilinear')\n",
        "plt.axis('off')\n",
        "plt.title('Most frequent words in the dataset',fontsize = 19)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7062eec",
      "metadata": {
        "id": "e7062eec"
      },
      "source": [
        "# Vectorization:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cfa88fa1",
      "metadata": {
        "id": "cfa88fa1"
      },
      "outputs": [],
      "source": [
        "vect = TfidfVectorizer(ngram_range = (1,2)).fit(covid_hate['Text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d3d5e6f",
      "metadata": {
        "id": "4d3d5e6f"
      },
      "outputs": [],
      "source": [
        "feature_names = vect.get_feature_names_out()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94bb11ec",
      "metadata": {
        "id": "94bb11ec"
      },
      "outputs": [],
      "source": [
        "vect = TfidfVectorizer(ngram_range = (1,3)).fit(covid_hate['Text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c9b7283",
      "metadata": {
        "id": "0c9b7283"
      },
      "outputs": [],
      "source": [
        "feature_names = vect.get_feature_names_out()\n",
        "print(\"Number of features: {}\\n\".format(len(feature_names)))\n",
        "print(\"First 20 fetures: \\n{}\".format(feature_names[:20]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d5e90cb5",
      "metadata": {
        "id": "d5e90cb5"
      },
      "source": [
        "# Train-Test split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dce34241",
      "metadata": {
        "id": "dce34241"
      },
      "outputs": [],
      "source": [
        "x = covid_hate['Text']\n",
        "y = covid_hate['label']\n",
        "X = vect.transform(x);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5f9bdef",
      "metadata": {
        "id": "d5f9bdef"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the dataset into training (60%) and combined validation+test set (40%)\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
        "\n",
        "# Further split the combined validation+test set into validation (50%) and test (50%)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "# Verify the sizes of the splits\n",
        "print(f\"Training set size: {X_train.shape[0]}\")\n",
        "print(f\"Validation set size: {X_val.shape[0]}\")\n",
        "print(f\"Test set size: {X_test.shape[0]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9799bca",
      "metadata": {
        "id": "b9799bca"
      },
      "source": [
        "# logistic Regression Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4616005",
      "metadata": {
        "id": "e4616005"
      },
      "outputs": [],
      "source": [
        "model = LogisticRegression()\n",
        "model.fit(X_train,y_train)\n",
        "model_train = model.predict(X_train)\n",
        "model_pred = model.predict(X_val)\n",
        "model_train_acc = accuracy_score(model_train,y_train)\n",
        "model_acc = accuracy_score(model_pred,y_val)\n",
        "print(\"Train accuracy: {:.2f}%\".format(model_train_acc*100))\n",
        "print(\"Validation accuracy: {:.2f}%\".format(model_acc*100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "823d8377",
      "metadata": {
        "id": "823d8377"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6cd5c68a",
      "metadata": {
        "id": "6cd5c68a"
      },
      "outputs": [],
      "source": [
        "#Define the parameter grid for GridSearchCV\n",
        "param_grid = {'C': [500, 10, 1.0, 0.1, 0.01], 'solver': ['newton-cg', 'lbfgs', 'liblinear']}\n",
        "\n",
        "#Create the GridSearchCV object\n",
        "grid = GridSearchCV(LogisticRegression(max_iter=1000), param_grid, cv=5)\n",
        "\n",
        "#Measure training time\n",
        "start_time = time.time()\n",
        "grid.fit(X_train, y_train)\n",
        "end_time = time.time()\n",
        "training_time1 = end_time - start_time\n",
        "\n",
        "#Best model after grid search\n",
        "best_model = grid.best_estimator_\n",
        "\n",
        "#Measure inference time on a subset of the test data\n",
        "sample_size = 355  # You can adjust this size based on your requirements\n",
        "sample_x_test = X_test[:sample_size]\n",
        "\n",
        "start_inference_time = time.time()\n",
        "_ = best_model.predict(sample_x_test)\n",
        "end_inference_time = time.time()\n",
        "inference_time1 = end_inference_time - start_inference_time\n",
        "\n",
        "# Training and validation accuracy\n",
        "train_predictions = best_model.predict(X_train)\n",
        "val_predictions = best_model.predict(X_val)\n",
        "\n",
        "training_accuracy1 = accuracy_score(y_train, train_predictions)\n",
        "validation_accuracy1 = accuracy_score(y_val, val_predictions)\n",
        "\n",
        "# Training loss\n",
        "train_proba = best_model.predict_proba(X_train)\n",
        "training_loss1 = log_loss(y_train, train_proba)\n",
        "\n",
        "# Model complexity (number of parameters)\n",
        "num_parameters1 = best_model.coef_.size + best_model.intercept_.size\n",
        "\n",
        "# Print results\n",
        "print(f\"Best Cross Validation score: {grid.best_score_:.2f}\")\n",
        "print(f\"Best Parameters: {grid.best_params_}\")\n",
        "print(f\"Training time: {training_time1:.2f} seconds\")\n",
        "print(f\"Inference time on {sample_size} samples: {inference_time1:.2f} seconds\")\n",
        "print(f\"Number of trainable parameters: {num_parameters1}\")\n",
        "print(f\"Training loss: {training_loss1:.4f}\")\n",
        "print(f\"Training accuracy: {training_accuracy1 * 100:.2f}%\")\n",
        "print(f\"Validation accuracy: {validation_accuracy1 * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "496e6fae",
      "metadata": {
        "id": "496e6fae"
      },
      "outputs": [],
      "source": [
        "# Get predictions for the validation set using the best model\n",
        "y_pred = best_model.predict(X_val)\n",
        "\n",
        "# Compute the confusion matrix\n",
        "cm = confusion_matrix(y_val, y_pred, labels=best_model.classes_)\n",
        "\n",
        "# Create a ConfusionMatrixDisplay object\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=best_model.classes_)\n",
        "\n",
        "# Plot the confusion matrix\n",
        "plt.figure(figsize=(10, 7))\n",
        "disp.plot(cmap=plt.cm.Blues, values_format='d')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "114d2845",
      "metadata": {
        "id": "114d2845"
      },
      "source": [
        "# Random Forest Model:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4d033fc",
      "metadata": {
        "id": "c4d033fc"
      },
      "outputs": [],
      "source": [
        "# Initialize the RandomForestClassifier with the specified parameters\n",
        "rf_model = RandomForestClassifier(max_depth=150, n_estimators=19, random_state=10)\n",
        "\n",
        "# Measure training time\n",
        "start_time = time.time()\n",
        "rf_model.fit(X_train, y_train)\n",
        "end_time = time.time()\n",
        "training_time2 = end_time - start_time\n",
        "\n",
        "# Measure inference time on a subset of the test data\n",
        "sample_size = 355\n",
        "sample_x_val = X_val[:sample_size]\n",
        "\n",
        "start_inference_time = time.time()\n",
        "_ = rf_model.predict(sample_x_test)\n",
        "end_inference_time = time.time()\n",
        "inference_time2 = end_inference_time - start_inference_time\n",
        "\n",
        "# Training accuracy\n",
        "rf_model_train = rf_model.predict(X_train)\n",
        "training_accuracy2 = accuracy_score(y_train, rf_model_train)\n",
        "\n",
        "# Validation accuracy\n",
        "rf_model_val = rf_model.predict(X_val)\n",
        "validation_accuracy2 = accuracy_score(y_val, rf_model_val)\n",
        "\n",
        "# Training loss\n",
        "train_proba = rf_model.predict_proba(X_train)\n",
        "training_loss2 = log_loss(y_train, train_proba)\n",
        "\n",
        "# Model complexity (number of parameters)\n",
        "# For RandomForest, model complexity can be estimated by the number of trees and their depth.\n",
        "num_trees = len(rf_model.estimators_)\n",
        "average_depth = np.mean([tree.tree_.max_depth for tree in rf_model.estimators_])\n",
        "model_complexity = f\"Number of trees: {num_trees}, Average tree depth: {average_depth:.2f}\"\n",
        "\n",
        "# Print results\n",
        "print(f\"Training time: {training_time2:.2f} seconds\")\n",
        "print(f\"Inference time on {sample_size} samples: {inference_time2:.2f} seconds\")\n",
        "print(f\"Model complexity: {model_complexity}\")\n",
        "print(f\"Training loss: {training_loss2:.4f}\")\n",
        "print(f\"Training accuracy: {training_accuracy2 * 100:.2f}%\")\n",
        "print(f\"Validation accuracy: {validation_accuracy2 * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6712314",
      "metadata": {
        "id": "f6712314"
      },
      "outputs": [],
      "source": [
        "# Compute confusion matrix\n",
        "y_pred = rf_model.predict(X_val)\n",
        "cm = confusion_matrix(y_val, y_pred)\n",
        "\n",
        "# Create and display confusion matrix\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "plt.figure(figsize=(10, 7))\n",
        "disp.plot(cmap=plt.cm.Blues, values_format='d')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "48aad041",
      "metadata": {
        "id": "48aad041"
      },
      "source": [
        "# Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1abdcae6",
      "metadata": {
        "id": "1abdcae6"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Define the model\n",
        "model2 = Sequential([\n",
        "    Dense(256, activation='relu', name='L1', kernel_regularizer=l2(0.001)),\n",
        "    Dropout(0.3),\n",
        "    Dense(128, activation='relu', name='L2', kernel_regularizer=l2(0.001)),\n",
        "    Dropout(0.3),\n",
        "    Dense(64, activation='relu', name='L3', kernel_regularizer=l2(0.001)),\n",
        "    Dropout(0.3),\n",
        "    Dense(32, activation='relu', name='L4', kernel_regularizer=l2(0.001)),\n",
        "    Dropout(0.3),\n",
        "    Dense(2, activation='softmax', name='Output')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model2.compile(\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Define early stopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
        "\n",
        "# Measure training time\n",
        "start_time = time.time()\n",
        "history = model2.fit(X_train, y_train, epochs=200, validation_split=0.2, callbacks=[early_stopping])\n",
        "end_time = time.time()\n",
        "training_time3 = end_time - start_time\n",
        "\n",
        "# Measure inference time on a subset of the test data\n",
        "sample_size = 355  # You can adjust this size based on your requirements\n",
        "sample_x_val = X_val[:sample_size]\n",
        "\n",
        "start_inference_time = time.time()\n",
        "_ = model2.predict(sample_x_val)\n",
        "end_inference_time = time.time()\n",
        "inference_time3 = end_inference_time - start_inference_time\n",
        "\n",
        "# Get model complexity (number of trainable parameters)\n",
        "num_parameters = model2.count_params()\n",
        "\n",
        "# Evaluate the model on training and validation data\n",
        "train_loss3, train_accuracy3 = model2.evaluate(X_train, y_train, verbose=0)\n",
        "val_loss3, val_accuracy3 = model2.evaluate(X_val, y_val, verbose=0)\n",
        "\n",
        "# Print the results\n",
        "print(f\"Training time: {training_time3:.2f} seconds\")\n",
        "print(f\"Inference time on {sample_size} samples: {inference_time3:.2f} seconds\")\n",
        "print(f\"Number of trainable parameters: {num_parameters}\")\n",
        "print(f\"Training loss: {train_loss3:.4f}\")\n",
        "print(f\"Training accuracy: {train_accuracy3 * 100:.2f}%\")\n",
        "print(f\"Validation loss: {val_loss3:.4f}\")\n",
        "print(f\"Validation accuracy: {val_accuracy3 * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62334f09",
      "metadata": {
        "id": "62334f09"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Extract loss values from the history object\n",
        "train_loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "# Plot both training and validation loss curves\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(train_loss, label='Training Loss', color='g')\n",
        "plt.plot(val_loss, label='Validation Loss', color='b')\n",
        "plt.title('Training and Validation Loss Curve')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b60f649d",
      "metadata": {
        "id": "b60f649d"
      },
      "outputs": [],
      "source": [
        "# Make predictions on the validation data\n",
        "y_pred = np.argmax(model2.predict(X_val), axis=1)\n",
        "\n",
        "# Compute the confusion matrix\n",
        "cm = confusion_matrix(y_val, y_pred)\n",
        "\n",
        "# Create a ConfusionMatrixDisplay object\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "\n",
        "# Plot the confusion matrix\n",
        "plt.figure(figsize=(10, 7))\n",
        "disp.plot(cmap=plt.cm.Blues)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57904638",
      "metadata": {
        "id": "57904638"
      },
      "source": [
        "# Gradient Boosting Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c42008d",
      "metadata": {
        "id": "4c42008d"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "# Initialize the Gradient Boosting model\n",
        "gb_model = GradientBoostingClassifier(random_state=42)\n",
        "\n",
        "# Measure training time\n",
        "start_time = time.time()\n",
        "\n",
        "# Fit the model on the training data\n",
        "gb_model.fit(X_train, y_train)\n",
        "\n",
        "# Calculate training time\n",
        "training_time4 = time.time() - start_time\n",
        "\n",
        "# Predict on the training set\n",
        "gb_train_pred = gb_model.predict(X_train)\n",
        "gb_train_pred_proba = gb_model.predict_proba(X_train)\n",
        "\n",
        "# Predict on the validation/test set\n",
        "gb_test_pred = gb_model.predict(X_val)\n",
        "gb_test_pred_proba = gb_model.predict_proba(X_val)\n",
        "\n",
        "# Calculate accuracy for training and validation/test sets\n",
        "gb_train_acc4 = accuracy_score(y_train, gb_train_pred)\n",
        "gb_test_acc4 = accuracy_score(y_val, gb_test_pred)\n",
        "\n",
        "# Calculate log loss (cross-entropy loss) for training and validation/test sets\n",
        "gb_train_loss4 = log_loss(y_train, gb_train_pred_proba)\n",
        "gb_test_loss4 = log_loss(y_val, gb_test_pred_proba)\n",
        "\n",
        "# Calculate the number of trainable parameters\n",
        "# This calculation is based on the number of estimators and the depth of each tree.\n",
        "num_estimators = gb_model.n_estimators\n",
        "# Each tree in GradientBoostingClassifier typically has several nodes,\n",
        "# but counting exact parameters is non-trivial. You can approximate or ignore for practical purposes.\n",
        "\n",
        "# Measure inference time\n",
        "start_time_inference = time.time()\n",
        "_ = gb_model.predict(X_val)  # Or use X_train if you want to measure on training set\n",
        "inference_time4 = time.time() - start_time_inference\n",
        "\n",
        "# Print results\n",
        "print(\"GB Train accuracy: {:.2f}%\".format(gb_train_acc4 * 100))\n",
        "print(\"GB Validation accuracy: {:.2f}%\".format(gb_test_acc4 * 100))\n",
        "print(\"GB Train loss: {:.4f}\".format(gb_train_loss4))\n",
        "print(\"GB Test loss: {:.4f}\".format(gb_test_loss4))\n",
        "print(\"Training time: {:.4f} seconds\".format(training_time4))\n",
        "print(\"Inference time: {:.4f} seconds\".format(inference_time4))\n",
        "print(\"Number of estimators: {}\".format(num_estimators))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a237006f",
      "metadata": {
        "id": "a237006f"
      },
      "outputs": [],
      "source": [
        "# Prepare lists to store losses\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "\n",
        "# Compute losses for each stage\n",
        "for stage in gb_model.staged_predict_proba(X_train):\n",
        "    train_losses.append(log_loss(y_train, stage))\n",
        "\n",
        "for stage in gb_model.staged_predict_proba(X_val):\n",
        "    val_losses.append(log_loss(y_val, stage))\n",
        "\n",
        "# Plotting the loss curves\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Plot training loss\n",
        "plt.plot(range(1, len(train_losses) + 1), train_losses, label='Training Loss', color='blue')\n",
        "\n",
        "# Plot validation loss\n",
        "plt.plot(range(1, len(val_losses) + 1), val_losses, label='Validation Loss', color='red')\n",
        "\n",
        "plt.xlabel('Number of Estimators')\n",
        "plt.ylabel('Log Loss')\n",
        "plt.title('Training and Validation Loss Curves')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b5fd6ea",
      "metadata": {
        "id": "1b5fd6ea"
      },
      "outputs": [],
      "source": [
        "train_conf_matrix = confusion_matrix(y_train, gb_train_pred)\n",
        "ConfusionMatrixDisplay(train_conf_matrix).plot()\n",
        "plt.title(\"Training Confusion Matrix\")\n",
        "plt.show()\n",
        "\n",
        "val_conf_matrix = confusion_matrix(y_val, gb_test_pred)\n",
        "ConfusionMatrixDisplay(val_conf_matrix).plot()\n",
        "plt.title(\"Validation Confusion Matrix\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f0bf17b",
      "metadata": {
        "id": "0f0bf17b"
      },
      "source": [
        "# Neural Network + MHA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c40e1975",
      "metadata": {
        "id": "c40e1975"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import numpy as np\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, MultiHeadAttention, LayerNormalization, Input, Add, Flatten, Reshape\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Define the input shape based on your TF-IDF vectors\n",
        "input_shape = X_train.shape[1]\n",
        "\n",
        "# Create a functional model to integrate MHA with increased regularization and dropout\n",
        "input_layer = Input(shape=(input_shape,))\n",
        "x = Dense(256, activation='relu', kernel_regularizer=l2(0.01))(input_layer)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(128, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(64, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(32, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
        "x = Dropout(0.5)(x)\n",
        "\n",
        "x = Reshape((4, 8))(x)  # Reshape for MultiHeadAttention layer\n",
        "\n",
        "# Add the Multi-Head Attention layer with fewer heads\n",
        "mha_output = MultiHeadAttention(num_heads=2, key_dim=16)(x, x)\n",
        "mha_output = LayerNormalization(epsilon=1e-6)(mha_output)\n",
        "mha_output = Add()([x, mha_output])\n",
        "\n",
        "# Flatten the output of the MHA layer before passing it to Dense layers\n",
        "flattened_output = Flatten()(mha_output)\n",
        "\n",
        "x = Dense(64, activation='relu', kernel_regularizer=l2(0.01))(flattened_output)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(32, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
        "x = Dropout(0.5)(x)\n",
        "\n",
        "output_layer = Dense(2, activation='softmax')(x)\n",
        "\n",
        "# Define the model\n",
        "model = Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "# Compile the model with a lower learning rate\n",
        "model.compile(\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "    optimizer=Adam(learning_rate=0.00005),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Early stopping with reduced patience\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "# Measure training time\n",
        "start_time = time.time()\n",
        "history = model.fit(X_train, y_train, epochs=200, validation_split=0.2, callbacks=[early_stopping])\n",
        "end_time = time.time()\n",
        "training_time5 = end_time - start_time\n",
        "\n",
        "# Measure inference time on the validation data\n",
        "start_inference_time = time.time()\n",
        "Val_predictions = model.predict(X_val)\n",
        "end_inference_time = time.time()\n",
        "inference_time5 = end_inference_time - start_inference_time\n",
        "\n",
        "# Calculate training accuracy\n",
        "train_predictions = model.predict(X_train)\n",
        "train_pred_labels = np.argmax(train_predictions, axis=1)\n",
        "train_accuracy5 = accuracy_score(y_train, train_pred_labels)\n",
        "\n",
        "# Calculate validation accuracy\n",
        "Val_pred_labels = np.argmax(Val_predictions, axis=1)\n",
        "Val_accuracy5 = accuracy_score(y_val, Val_pred_labels)\n",
        "\n",
        "# Get the number of trainable parameters\n",
        "num_parameters = model.count_params()\n",
        "\n",
        "# Get the final training and validation loss from history\n",
        "training_loss5 = history.history['loss'][-1]\n",
        "validation_loss5 = history.history['val_loss'][-1]\n",
        "\n",
        "print(f'Training time: {training_time5:.2f} seconds')\n",
        "print(f'Inference time on validation set: {inference_time5:.2f} seconds')\n",
        "print(f'Number of trainable parameters: {num_parameters}')\n",
        "print(f'Training loss: {training_loss5:.4f}')\n",
        "print(f'Validation loss: {validation_loss5:.4f}')\n",
        "print(f'Training accuracy: {train_accuracy5 * 100:.2f}%')\n",
        "print(f'Validation accuracy: {Val_accuracy5 * 100:.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "284a83b2",
      "metadata": {
        "id": "284a83b2"
      },
      "outputs": [],
      "source": [
        "# Extract loss values\n",
        "epochs = range(1, len(history.history['loss']) + 1)\n",
        "train_loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "# Plot training and validation loss curves\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(epochs, train_loss, 'b-', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'r-', label='Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Validation Loss Curves')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b519c00",
      "metadata": {
        "id": "1b519c00"
      },
      "outputs": [],
      "source": [
        "# Training confusion matrix\n",
        "train_conf_matrix = confusion_matrix(y_test,train_predictions)\n",
        "\n",
        "# Validation confusion matrix\n",
        "val_conf_matrix = confusion_matrix(y_val, Val_pred_labels)\n",
        "\n",
        "# Function to plot confusion matrix\n",
        "def plot_confusion_matrix(conf_matrix, title):\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
        "    plt.title(title)\n",
        "    plt.ylabel('Actual Label')\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.show()\n",
        "\n",
        "# Plot confusion matrices\n",
        "plot_confusion_matrix(train_conf_matrix, 'Training Confusion Matrix')\n",
        "plot_confusion_matrix(val_conf_matrix, 'Validation Confusion Matrix')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "702d1104",
      "metadata": {
        "id": "702d1104"
      },
      "source": [
        "# Bert model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4583d2f5",
      "metadata": {
        "id": "4583d2f5"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Input\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from transformers import BertTokenizer, TFBertModel\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Assuming 'covid_hate' is your DataFrame and 'Text' is your column with raw text data\n",
        "x_train_raw = covid_hate['Text'].tolist()\n",
        "x_test_raw = covid_hate['Text'].tolist()\n",
        "\n",
        "# Extract labels from your dataset\n",
        "y_train = covid_hate['label'].values  # Replace 'label' with your actual label column name\n",
        "y_test = covid_hate['label'].values  # Replace 'label' with your actual label column name\n",
        "\n",
        "# Load BERT tokenizer and model\n",
        "model_name = 'bert-base-uncased'\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "bert_model = TFBertModel.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and process text data in smaller batches to avoid high memory usage\n",
        "def tokenize_texts(texts, tokenizer, max_length=128):\n",
        "    return tokenizer(\n",
        "        texts,\n",
        "        max_length=max_length,\n",
        "        padding='max_length',\n",
        "        truncation=True,\n",
        "        return_tensors='tf'\n",
        "    )\n",
        "\n",
        "# Use smaller batches to handle large datasets efficiently\n",
        "def process_in_batches(texts, tokenizer, batch_size=32, max_length=128):\n",
        "    embeddings = []\n",
        "    for i in range(0, len(texts), batch_size):\n",
        "        batch_texts = texts[i:i+batch_size]\n",
        "        batch_tokens = tokenize_texts(batch_texts, tokenizer, max_length)\n",
        "        batch_embeddings = get_bert_embeddings(batch_tokens, bert_model)\n",
        "        embeddings.append(batch_embeddings)\n",
        "    return tf.concat(embeddings, axis=0)\n",
        "\n",
        "# Extract BERT embeddings\n",
        "def get_bert_embeddings(tokens, model):\n",
        "    outputs = model(input_ids=tokens['input_ids'], attention_mask=tokens['attention_mask'])\n",
        "    return outputs.last_hidden_state[:, 0, :]  # Use [CLS] token representation\n",
        "\n",
        "# Process data in batches\n",
        "x_train_embeddings = process_in_batches(x_train_raw, tokenizer)\n",
        "x_test_embeddings = process_in_batches(x_test_raw, tokenizer)\n",
        "\n",
        "# Define MLP Model for Classification\n",
        "input_shape = x_train_embeddings.shape[1]\n",
        "input_layer = Input(shape=(input_shape,))\n",
        "x = Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001))(input_layer)\n",
        "x = Dropout(0.3)(x)\n",
        "x = Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001))(x)\n",
        "x = Dropout(0.3)(x)\n",
        "x = Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001))(x)\n",
        "x = Dropout(0.3)(x)\n",
        "x = Dense(32, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001))(x)\n",
        "x = Dropout(0.3)(x)\n",
        "output_layer = Dense(2, activation='softmax')(x)\n",
        "\n",
        "# Define the model\n",
        "mlp_model = Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "# Compile the model\n",
        "mlp_model.compile(\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "    optimizer=tf.keras.optimizers.Adam(0.0001),  # Lower learning rate\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Define early stopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "# Measure training time\n",
        "start_time = time.time()\n",
        "history = mlp_model.fit(x_train_embeddings, y_train, epochs=200, validation_split=0.2, callbacks=[early_stopping])\n",
        "end_time = time.time()\n",
        "training_time6 = end_time - start_time\n",
        "\n",
        "# Measure inference time on the test data\n",
        "start_inference_time = time.time()\n",
        "test_loss, test_acc = mlp_model.evaluate(x_test_embeddings, y_test)\n",
        "end_inference_time = time.time()\n",
        "inference_time6 = end_inference_time - start_inference_time\n",
        "\n",
        "# Manually predict labels for the test set (optional, but not necessary if using evaluate)\n",
        "test_predictions = mlp_model.predict(x_test_embeddings)\n",
        "test_pred_labels = np.argmax(test_predictions, axis=1)\n",
        "test_accuracy_manual = accuracy_score(y_test, test_pred_labels)\n",
        "\n",
        "# Calculate training accuracy\n",
        "train_predictions = mlp_model.predict(x_train_embeddings)\n",
        "train_pred_labels = np.argmax(train_predictions, axis=1)\n",
        "train_accuracy6 = accuracy_score(y_train, train_pred_labels)\n",
        "\n",
        "# Calculate validation accuracy (from history)\n",
        "val_predictions = mlp_model.predict(x_train_embeddings[int(len(x_train_embeddings) * 0.8):])\n",
        "val_pred_labels = np.argmax(val_predictions, axis=1)\n",
        "y_val = y_train[int(len(y_train) * 0.8):]\n",
        "val_accuracy6 = accuracy_score(y_val, val_pred_labels)\n",
        "\n",
        "# Get the number of trainable parameters\n",
        "num_parameters = mlp_model.count_params()\n",
        "\n",
        "# Get the final training and validation loss from history\n",
        "training_loss6 = history.history['loss'][-1]\n",
        "validation_loss6 = history.history['val_loss'][-1]\n",
        "\n",
        "# Print all the metrics\n",
        "print(f'Training time: {training_time6:.2f} seconds')\n",
        "print(f'Inference time on test set: {inference_time6:.2f} seconds')\n",
        "print(f'Number of trainable parameters: {num_parameters}')\n",
        "print(f'Training loss: {training_loss6:.4f}')\n",
        "print(f'Validation loss: {validation_loss6:.4f}')\n",
        "print(f'Training accuracy: {train_accuracy6 * 100:.2f}%')\n",
        "print(f'Validation accuracy: {val_accuracy6 * 100:.2f}%')\n",
        "print(f'Test accuracy (from evaluate): {test_acc * 100:.2f}%')\n",
        "print(f'Test accuracy (manual calculation): {test_accuracy_manual * 100:.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "320f1641",
      "metadata": {
        "id": "320f1641"
      },
      "outputs": [],
      "source": [
        "# Plot training & validation loss values\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d5e6297",
      "metadata": {
        "id": "1d5e6297"
      },
      "outputs": [],
      "source": [
        "# Predict on the test set\n",
        "y_test_pred = np.argmax(mlp_model.predict(x_test_embeddings), axis=1)\n",
        "\n",
        "# Generate the confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_test_pred)\n",
        "\n",
        "# Plot confusion matrix using seaborn heatmap\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3110d30a",
      "metadata": {
        "id": "3110d30a"
      },
      "outputs": [],
      "source": [
        "# Create a dictionary to store model performance metrics\n",
        "model_comparison = {\n",
        "    'Model': ['Logistic Regression', 'Random Forest', 'Neural Network', 'Gradient Boosting', 'Neural Network+MHA', 'BERT'],\n",
        "    'Training Accuracy': [training_accuracy1, training_accuracy2, train_accuracy3, gb_train_acc4, train_accuracy5, train_accuracy6],\n",
        "    'Validation Accuracy': [validation_accuracy1, validation_accuracy2, val_accuracy3, gb_test_acc4, Val_accuracy5, test_acc],\n",
        "    'Training Time (s)': [training_time1, training_time2, training_time3, training_time4, training_time5, training_time6],\n",
        "    'Inference Time': [inference_time1, inference_time2, inference_time3, inference_time4, inference_time5, inference_time6]\n",
        "}\n",
        "\n",
        "# Create DataFrame\n",
        "comparison_df = pd.DataFrame(model_comparison)\n",
        "\n",
        "# Display the table\n",
        "comparison_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03404c2d",
      "metadata": {
        "id": "03404c2d"
      },
      "outputs": [],
      "source": [
        "# Set style for the plot\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# Plot comparison of validation accuracy for different models\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x='Model', y='Validation Accuracy', data=comparison_df)\n",
        "\n",
        "plt.title('Validation Accuracy Comparison')\n",
        "plt.xlabel('Model')\n",
        "plt.ylabel('Validation Accuracy')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "z-hTWNMKwSX6",
      "metadata": {
        "id": "z-hTWNMKwSX6"
      },
      "source": [
        "# Saving the trained Model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lqoSKeQexjOt",
      "metadata": {
        "id": "lqoSKeQexjOt"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "filename = 'trained_model.sav'\n",
        "pickle.dump(gb_model,open(filename,'wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "KAMi1Omdxyyn",
      "metadata": {
        "id": "KAMi1Omdxyyn"
      },
      "outputs": [],
      "source": [
        "#Loading the saved model:\n",
        "loaded_model = pickle.load(open('trained_model.sav','rb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sse6K83o0y1r",
      "metadata": {
        "id": "sse6K83o0y1r"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
